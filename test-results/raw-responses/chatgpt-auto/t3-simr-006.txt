Here’s a clean “working” approximation for the **primary outcome** under a random‐intercept linear mixed model with 4 equally spaced repeated measures and a constant treatment effect over time.

## 1) Convert your variance components to an ICC

Random intercept SD (=0.5 \Rightarrow \sigma_b^2 = 0.25)
Residual SD (=1.0 \Rightarrow \sigma_e^2 = 1.00)

Total marginal variance per observation:
[
\sigma^2 = \sigma_b^2+\sigma_e^2 = 0.25+1=1.25
]

Within-subject (compound symmetry) correlation:
[
\rho = \frac{\sigma_b^2}{\sigma_b^2+\sigma_e^2}=\frac{0.25}{1.25}=0.20
]

## 2) Design effect from correlation (how much repetition helps)

With (m=4) timepoints, the usual CS “design effect” is:
[
DE = 1+(m-1)\rho = 1+3(0.20)=1.60
]

So (m) repeated measures contribute like an **effective** number of independent observations per subject:
[
\frac{m}{DE}=\frac{4}{1.6}=2.5
]
i.e., each subject ≈ **2.5 independent observations** worth of information for the treatment main effect (under this simplified setting).

## 3) Start from the independent two-sample mean comparison, then adjust

Assume two-sided (\alpha=0.05), power (=0.80).
[
z_{1-\alpha/2}=1.96,\quad z_{1-\beta}=0.84
]

For a single independent measurement per subject, required per-arm sample size:
[
n_{\text{indep}}=\frac{2(z_{1-\alpha/2}+z_{1-\beta})^2\sigma^2}{\Delta^2}
=\frac{2(1.96+0.84)^2(1.25)}{0.4^2}
\approx 122.6
]

Now “credit” the repeated measures by dividing by (m/DE=2.5):
[
n \approx \frac{122.6}{2.5} \approx 49.1
]

## Answer

**About (\boxed{50}) subjects per group** for **80% power** to detect a **treatment effect of 0.4 on the primary outcome** (two-sided (\alpha=0.05)), under the stated random-intercept + residual model with 4 timepoints.

### Notes (important)

* The **cross-outcome correlation (r=0.6)** and the secondary effect (0.3) typically **do not materially increase power for the primary treatment effect** unless you’re leveraging the secondary outcome to reduce variance (e.g., via missing-data recovery, strong shared random effects structure, or using it effectively like an auxiliary variable). So **50/arm is a reasonable conservative planning number**.
* If you expect attrition, inflate: e.g., 15% dropout ⇒ (50/0.85 \approx 59) per arm.

If you tell me whether the treatment effect is assumed **constant across time** (main effect) or you’re really testing a **treatment×time interaction / slope difference**, the sample size can shift a lot.
